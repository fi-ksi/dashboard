{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KSI monitoring: úlohy\n",
    "\n",
    "V tomto souboru se nachází hlavní tabulka statistik týkajících se úloh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-02 19:20:55.498887\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict, namedtuple\n",
    "from sqlalchemy import func, distinct, text, and_\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import util\n",
    "from util.year import year as current_year\n",
    "from db import session\n",
    "import model\n",
    "from datetime import datetime\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "plt.rcParams['figure.figsize'] = [8, 6]\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = session.query(\n",
    "    model.Task,\n",
    "    func.count(distinct(model.User.id)).label('evals_count'),\n",
    ").\\\n",
    "    join(model.Task.r_wave).filter(model.Wave.year == current_year.id).\\\n",
    "    join(model.Task.modules).\\\n",
    "    join(model.Module.evaluations).\\\n",
    "    join(model.Evaluation.r_user).\\\n",
    "    filter(model.User.role == 'participant')\n",
    "\n",
    "evaluations_per_task = evaluations.\\\n",
    "    group_by(model.Task).order_by(model.Wave.id, model.Task.id)\n",
    "\n",
    "evaluations_per_task_d = {\n",
    "    task: evals_count\n",
    "    for (task, evals_count) in evaluations_per_task.all()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_evaluations = evaluations_per_task.\\\n",
    "    filter(model.Evaluation.ok == True)\n",
    "\n",
    "successful_evaluations_d = {\n",
    "    task: evals_count\n",
    "    for (task, evals_count) in successful_evaluations.all()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "per_module = session.query(\n",
    "    model.Evaluation.user.label('user_id'),\n",
    "    func.count(model.Evaluation.id).label('eval_count'),\n",
    ").\\\n",
    "    join(model.Evaluation.r_module).join(model.Module.r_task).\\\n",
    "    join(model.Task.r_wave).\\\n",
    "    filter(model.Wave.year == current_year.id).\\\n",
    "    group_by(model.Evaluation.user,\n",
    "             model.Evaluation.module).subquery()\n",
    "\n",
    "EVAL_LIMITS = [10, 30, 50]\n",
    "problematic_tasks = {\n",
    "    limit: {\n",
    "        task: evals_count\n",
    "        for (task, evals_count) in (\n",
    "            evaluations.\n",
    "            filter(model.Evaluation.ok == False).\n",
    "            join(per_module, per_module.c.user_id == model.User.id).\\\n",
    "            group_by(model.Task).\\\n",
    "            filter(per_module.c.eval_count > limit).all()\n",
    "        )\n",
    "    }\n",
    "    for limit in EVAL_LIMITS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_count = session.query(\n",
    "    model.Task,\n",
    "    func.count(model.Post.id)\n",
    ").\\\n",
    "    join(model.Task.r_wave).\\\n",
    "    filter(model.Wave.year == current_year.id).\\\n",
    "    join(model.Task.discussion_posts).\\\n",
    "    group_by(model.Task).\\\n",
    "    all()\n",
    "\n",
    "posts_count_dict = {\n",
    "    task: count\n",
    "    for (task, count) in posts_count\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_waves = session.query(model.Wave).\\\n",
    "    filter(model.Wave.year == current_year.id).\\\n",
    "    order_by(model.Wave.index).all()\n",
    "\n",
    "large_tasks = util.task.large_tasks().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_evaluations_per_task_and_user = session.query(\n",
    "    model.Task,\n",
    "    model.User,\n",
    "    func.count(model.Evaluation.id),\n",
    ").\\\n",
    "    join(model.Task.r_wave).filter(model.Wave.year == current_year.id).\\\n",
    "    join(model.Task.modules).\\\n",
    "    join(model.Module.evaluations).\\\n",
    "    join(model.Evaluation.r_user).\\\n",
    "    filter(model.User.role == 'participant').\\\n",
    "    group_by(model.Task, model.User).\\\n",
    "    all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_evaluations_dict = {}\n",
    "for task, user, count in no_evaluations_per_task_and_user:\n",
    "    if task in no_evaluations_dict:\n",
    "        no_evaluations_dict[task].append(count)\n",
    "    else:    \n",
    "        no_evaluations_dict[task] = [count]\n",
    "        \n",
    "no_evaluations_avg = {\n",
    "    task: np.average(counts)\n",
    "    for task, counts in no_evaluations_dict.items()\n",
    "}\n",
    "\n",
    "no_evaluations_median = {\n",
    "    task: np.median(counts)\n",
    "    for task, counts in no_evaluations_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Nultá vlna"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_e354b096_b549_11e9_9ddd_54e1ad88a4c1\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >All Evaluations</th>        <th class=\"col_heading level0 col1\" >Successful Evaluations</th>        <th class=\"col_heading level0 col2\" >Successful/All ratio</th>        <th class=\"col_heading level0 col3\" >N.O. Users failing on task now</th>        <th class=\"col_heading level0 col4\" >N.O. Users with more than 10 unsucc. evaluations</th>        <th class=\"col_heading level0 col5\" >N.O. Users with more than 30 unsucc. evaluations</th>        <th class=\"col_heading level0 col6\" >N.O. Users with more than 50 unsucc. evaluations</th>        <th class=\"col_heading level0 col7\" >Discussion Posts Count</th>        <th class=\"col_heading level0 col8\" >Average N.O. Evaluations Per User</th>        <th class=\"col_heading level0 col9\" >Median N.O. Evaluations Per User</th>        <th class=\"col_heading level0 col10\" >Some Maximum Evaluations Counts</th>    </tr>    <tr>        <th class=\"index_name level0\" >Task</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "        </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2f4126cd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Stromy a algoritmy + vyvažování"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_e354b097_b549_11e9_9ddd_54e1ad88a4c1\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >All Evaluations</th>        <th class=\"col_heading level0 col1\" >Successful Evaluations</th>        <th class=\"col_heading level0 col2\" >Successful/All ratio</th>        <th class=\"col_heading level0 col3\" >N.O. Users failing on task now</th>        <th class=\"col_heading level0 col4\" >N.O. Users with more than 10 unsucc. evaluations</th>        <th class=\"col_heading level0 col5\" >N.O. Users with more than 30 unsucc. evaluations</th>        <th class=\"col_heading level0 col6\" >N.O. Users with more than 50 unsucc. evaluations</th>        <th class=\"col_heading level0 col7\" >Discussion Posts Count</th>        <th class=\"col_heading level0 col8\" >Average N.O. Evaluations Per User</th>        <th class=\"col_heading level0 col9\" >Median N.O. Evaluations Per User</th>        <th class=\"col_heading level0 col10\" >Some Maximum Evaluations Counts</th>    </tr>    <tr>        <th class=\"index_name level0\" >Task</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "        </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2f40d99ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_wave_stats(wave, max_evals_count):\n",
    "    tasks = [\n",
    "        (\n",
    "            task,\n",
    "            evaluations_per_task_d[task],\n",
    "            successful_evaluations_d[task],\n",
    "            successful_evaluations_d[task] / evaluations_per_task_d[task],\n",
    "            evaluations_per_task_d[task]-successful_evaluations_d[task],\n",
    "            problematic_tasks[10][task] if task in problematic_tasks[10] else 0,\n",
    "            problematic_tasks[30][task] if task in problematic_tasks[30] else 0,\n",
    "            problematic_tasks[50][task] if task in problematic_tasks[50] else 0,\n",
    "            posts_count_dict[task] if task in posts_count_dict else 0,\n",
    "            no_evaluations_avg[task] if task in no_evaluations_avg else '-',\n",
    "            no_evaluations_median[task] if task in no_evaluations_median else '-',\n",
    "            sorted(no_evaluations_dict[task])[-5:] if task in no_evaluations_dict else '-',\n",
    "        )\n",
    "        for task in evaluations_per_task_d\n",
    "        if task.wave == wave.id\n",
    "    ]\n",
    "    tasks.sort(key=lambda x: (x[0] in large_tasks, x[0].id))\n",
    "\n",
    "    df = pd.DataFrame(tasks, columns=[\n",
    "        'Task',\n",
    "        'All Evaluations',\n",
    "        'Successful Evaluations',\n",
    "        'Successful/All ratio',\n",
    "        'N.O. Users failing on task now',\n",
    "        'N.O. Users with more than 10 unsucc. evaluations',\n",
    "        'N.O. Users with more than 30 unsucc. evaluations',\n",
    "        'N.O. Users with more than 50 unsucc. evaluations',\n",
    "        'Discussion Posts Count',\n",
    "        'Average N.O. Evaluations Per User',\n",
    "        'Median N.O. Evaluations Per User',\n",
    "        'Some Maximum Evaluations Counts',\n",
    "    ]).set_index('Task')\n",
    "    \n",
    "    s = df.style\n",
    "    \n",
    "    s.background_gradient(subset=[\n",
    "        'N.O. Users failing on task now',\n",
    "        'N.O. Users with more than 10 unsucc. evaluations',\n",
    "        'N.O. Users with more than 30 unsucc. evaluations',\n",
    "        'N.O. Users with more than 50 unsucc. evaluations',\n",
    "        'Average N.O. Evaluations Per User',\n",
    "        'Median N.O. Evaluations Per User',        \n",
    "    ], cmap=sns.light_palette(\"red\", as_cmap=True))\n",
    "    \n",
    "    s.background_gradient(\n",
    "        subset=['Successful/All ratio'],\n",
    "        cmap=sns.light_palette(\"green\", as_cmap=True)\n",
    "    )\n",
    "    \n",
    "    s.background_gradient(\n",
    "        subset=['Discussion Posts Count'],\n",
    "        cmap=sns.light_palette(\"orange\", as_cmap=True)\n",
    "    )\n",
    "    \n",
    "    s.bar(subset=['All Evaluations'], color='#5fd65f', vmin=0, vmax=max_evals_count)\n",
    "    \n",
    "    s.format({\n",
    "        'Successful/All ratio': '{:,.1%}'.format,\n",
    "        'Average N.O. Evaluations Per User': '{:.2f}'.format,\n",
    "    })\n",
    "    \n",
    "    display(Markdown('## {name}'.format(name=wave.caption)))\n",
    "    display(s)\n",
    "\n",
    "max_evals_count = max(evaluations_per_task_d.values(), default=10)\n",
    "    \n",
    "for wave in all_waves:\n",
    "    show_wave_stats(wave, max_evals_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistika velkých úloh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "per_module = session.query(\n",
    "    model.Wave,\n",
    "    model.Task,\n",
    "    model.Evaluation.user.label('user_id'),\n",
    "    model.Evaluation.module.label('module_id'),\n",
    "    func.max(model.Evaluation.points).label('points'),\n",
    "    model.Module.max_points.label('max_points'),\n",
    ").\\\n",
    "    join(model.Evaluation.r_module).\\\n",
    "    filter(model.Module.type == model.ModuleType.GENERAL).\\\n",
    "    join(model.Module.r_task).join(model.Task.r_wave).\\\n",
    "    filter(model.Wave.year == current_year.id).\\\n",
    "    group_by(model.Task, model.Evaluation.user, model.Evaluation.id).\\\n",
    "    order_by(model.Wave.id)\n",
    "\n",
    "norm_points = [\n",
    "    pm.points / pm.max_points\n",
    "    for pm in per_module\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(per_module.all())\n",
    "if not df.empty:\n",
    "    df['norm_points'] = norm_points\n",
    "    grouped = df.groupby('Task')\n",
    "\n",
    "    per_task = pd.DataFrame(OrderedDict((\n",
    "        ('Wave', grouped.Wave.first()),\n",
    "        ('Solved count', grouped.user_id.count()),\n",
    "        ('Max Points', grouped.max_points.first()),\n",
    "        ('Points Average', grouped.points.mean()),\n",
    "        ('Points Median', grouped.points.median()),    \n",
    "        ('Points Average Normalized', grouped.norm_points.mean()),\n",
    "        ('Points Median Normalized', grouped.norm_points.median()),\n",
    "    )))\n",
    "    s = per_task.style\n",
    "    s.format({\n",
    "        'Points Average': '{:.2f}'.format,\n",
    "        'Points Average Normalized': '{:,.1%}'.format,\n",
    "        'Points Median Normalized': '{:,.1%}'.format,\n",
    "    })\n",
    "\n",
    "    s.background_gradient(subset=[\n",
    "        'Solved count',\n",
    "        'Points Average Normalized',\n",
    "        'Points Median Normalized',\n",
    "    ], cmap=sns.light_palette(\"green\", as_cmap=True))\n",
    "\n",
    "    s.background_gradient(subset=[\n",
    "        'Points Median',\n",
    "        'Points Average',\n",
    "    ], cmap=sns.light_palette(\"blue\", as_cmap=True))\n",
    "\n",
    "    display(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kolik řešitelů získalo kolik bodů za velké úlohy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    gained_points = pd.DataFrame(OrderedDict((\n",
    "        ('[9, inf)', df[df['points'] >= 9].groupby('Task').points.count()),    \n",
    "        ('[8–9)', df[(df['points'] >= 8) & (df['points'] < 9)].groupby('Task').points.count()),    \n",
    "        ('[6–8)', df[(df['points'] >= 6) & (df['points'] < 8)].groupby('Task').points.count()),\n",
    "        ('[4–6)', df[(df['points'] >= 4) & (df['points'] < 6)].groupby('Task').points.count()),\n",
    "\n",
    "        ('[0–4)', df[(df['points'] >= 0) & (df['points'] < 4)].groupby('Task').points.count()),\n",
    "    )))\n",
    "    gained_points.plot.bar(stacked=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Předchozí tabulka normalizovaná maximálním počtem bodů za úlohu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    gained_points_norm = pd.DataFrame(OrderedDict((\n",
    "        ('>90 %', df[df['norm_points'] >= .9].groupby('Task').norm_points.count()),    \n",
    "        ('[80 % – 90 %)', df[(df['norm_points'] >= .8) & (df['norm_points'] < .9)].groupby('Task').norm_points.count()),\n",
    "        ('[60 % – 80 %)', df[(df['norm_points'] >= .6) & (df['norm_points'] < .8)].groupby('Task').norm_points.count()),\n",
    "        ('[40 % – 60 %)', df[(df['norm_points'] >= .4) & (df['norm_points'] < .6)].groupby('Task').norm_points.count()),\n",
    "        ('[0 % – 40 %)', df[(df['norm_points'] >= 0) & (df['norm_points'] < .4)].groupby('Task').norm_points.count()),\n",
    "    )))\n",
    "    gained_points_norm.plot.bar(stacked=True);"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
